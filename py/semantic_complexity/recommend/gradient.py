"""
Gradient-based Recommender

ê· í˜•ì ìœ¼ë¡œ í–¥í•˜ëŠ” ë¦¬íŒ©í† ë§ ê¶Œì¥ì‚¬í•­ ìƒì„±
"""

from dataclasses import dataclass
from typing import Literal

from ..types import Axis, ModuleType, SandwichScore, get_canonical_profile
from ..simplex import (
    GradientDirection,
    EquilibriumStatus,
    check_equilibrium,
    calculate_deviation,
)
from ..analyzers import CognitiveResult


@dataclass
class Recommendation:
    """ë¦¬íŒ©í† ë§ ê¶Œì¥ì‚¬í•­"""
    axis: Axis
    priority: int  # 1 = ìµœìš°ì„ 
    action: str
    reason: str
    expected_impact: dict[str, float]  # {"ğŸ": -5, "ğŸ§€": +3, ...}
    target_equilibrium: bool  # Trueë©´ ê· í˜•ì  ë°©í–¥


# ============================================================
# ì¶•ë³„ ë¦¬íŒ©í† ë§ ì•¡ì…˜
# ============================================================

BREAD_ACTIONS = {
    "increase": [
        ("ì‹ ë¢° ê²½ê³„ ëª…ì‹œì  ì •ì˜ ì¶”ê°€", "Trust boundaryë¥¼ ì½”ë“œì— ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„"),
        ("ì¸ì¦/ì¸ê°€ ë°ì½”ë ˆì´í„° ì ìš©", "ì—”ë“œí¬ì¸íŠ¸ì— @authenticated ë“± ì ìš©"),
        ("ì…ë ¥ ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€", "ì™¸ë¶€ ì…ë ¥ì— ëŒ€í•œ ê²€ì¦ ë¡œì§ ì¶”ê°€"),
    ],
    "decrease": [
        ("ë³´ì•ˆ ë¡œì§ ë¶„ë¦¬", "ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì—ì„œ ë³´ì•ˆ ë¡œì§ ë¶„ë¦¬"),
        ("ê³µí†µ ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´ë¡œ ì¶”ì¶œ", "ë°˜ë³µë˜ëŠ” ë³´ì•ˆ ë¡œì§ì„ ë¯¸ë“¤ì›¨ì–´ë¡œ"),
    ],
}

CHEESE_ACTIONS = {
    "increase": [
        # ğŸ§€ increaseëŠ” ë“œë¬¸ ì¼€ì´ìŠ¤ (ë³µì¡ë„ê°€ ë„ˆë¬´ ë‚®ìŒ)
        ("ì ì ˆí•œ ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€", "ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬ ë¡œì§ ì¶”ê°€"),
    ],
    "decrease": [
        ("ì¤‘ì²© í‰íƒ„í™” (early return)", "ê¹Šì€ ì¤‘ì²©ì„ early returnìœ¼ë¡œ í‰íƒ„í™”"),
        ("í•¨ìˆ˜ ì¶”ì¶œ (Extract Function)", "ë³µì¡í•œ ë¸”ë¡ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ì¶”ì¶œ"),
        ("ì¡°ê±´ ë‹¨ìˆœí™”", "ë³µì¡í•œ ì¡°ê±´ì„ ëª…ëª…ëœ ë³€ìˆ˜ë¡œ ë¶„ë¦¬"),
        ("ìƒíƒœ ë¶„ë¦¬", "stateÃ—asyncÃ—retry ë¶„ë¦¬"),
        ("Switch â†’ ë‹¤í˜•ì„±", "switch/matchë¥¼ Strategy íŒ¨í„´ìœ¼ë¡œ"),
    ],
}

HAM_ACTIONS = {
    "increase": [
        ("Golden test ì¶”ê°€", "Critical pathì— ëŒ€í•œ golden test ì‘ì„±"),
        ("Contract test ì¶”ê°€", "API ê³„ì•½ í…ŒìŠ¤íŠ¸ ì‘ì„±"),
        ("Test fixture ì •ë¦¬", "í…ŒìŠ¤íŠ¸ ì½”ë“œ êµ¬ì¡°í™”"),
    ],
    "decrease": [
        # ğŸ¥“ decreaseëŠ” ë“œë¬¸ ì¼€ì´ìŠ¤ (í…ŒìŠ¤íŠ¸ê°€ ë„ˆë¬´ ë§ìŒ?!)
        ("ì¤‘ë³µ í…ŒìŠ¤íŠ¸ ì •ë¦¬", "ë¶ˆí•„ìš”í•œ ì¤‘ë³µ í…ŒìŠ¤íŠ¸ ì œê±°"),
    ],
}

AXIS_ACTIONS = {
    Axis.BREAD: BREAD_ACTIONS,
    Axis.CHEESE: CHEESE_ACTIONS,
    Axis.HAM: HAM_ACTIONS,
}


class GradientRecommender:
    """Gradient ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±ê¸°"""

    def __init__(
        self,
        current: SandwichScore,
        module_type: ModuleType,
        cognitive_result: CognitiveResult | None = None,
    ):
        self.current = current
        self.module_type = module_type
        self.profile = get_canonical_profile(module_type)
        self.cognitive_result = cognitive_result

    def recommend(self, max_recommendations: int = 3) -> list[Recommendation]:
        """
        ë¦¬íŒ©í† ë§ ê¶Œì¥ì‚¬í•­ ìƒì„±

        Args:
            max_recommendations: ìµœëŒ€ ê¶Œì¥ì‚¬í•­ ìˆ˜

        Returns:
            ìš°ì„ ìˆœìœ„ìˆœ ì •ë ¬ëœ ê¶Œì¥ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
        """
        status = check_equilibrium(self.current, self.profile)

        if status.in_equilibrium:
            return []  # ì´ë¯¸ ê· í˜•

        recommendations: list[Recommendation] = []

        for i, gradient in enumerate(status.gradients[:max_recommendations]):
            rec = self._create_recommendation(gradient, priority=i + 1)
            if rec:
                recommendations.append(rec)

        # stateÃ—asyncÃ—retry ìœ„ë°˜ ì‹œ ì¶”ê°€ ê¶Œì¥ì‚¬í•­
        if self.cognitive_result and self.cognitive_result.state_async_retry.violated:
            recommendations.insert(0, Recommendation(
                axis=Axis.CHEESE,
                priority=0,  # ìµœìš°ì„ 
                action="stateÃ—asyncÃ—retry ë¶„ë¦¬",
                reason="ì¸ì§€ ë¶ˆë³€ì¡°ê±´ ìœ„ë°˜ - ìƒíƒœ, ë¹„ë™ê¸°, ì¬ì‹œë„ ë¡œì§ì„ ë¶„ë¦¬í•´ì•¼ í•¨",
                expected_impact={"ğŸ§€": -20.0},
                target_equilibrium=True,
            ))

        return recommendations

    def _create_recommendation(
        self,
        gradient: GradientDirection,
        priority: int,
    ) -> Recommendation | None:
        """Gradientì—ì„œ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        actions = AXIS_ACTIONS.get(gradient.axis, {})
        direction_actions = actions.get(gradient.direction, [])

        if not direction_actions:
            return None

        action, reason = direction_actions[0]

        # Expected impact ê³„ì‚°
        impact_value = -gradient.magnitude if gradient.direction == "decrease" else gradient.magnitude
        impact = {str(gradient.axis): impact_value}

        return Recommendation(
            axis=gradient.axis,
            priority=priority,
            action=action,
            reason=reason,
            expected_impact=impact,
            target_equilibrium=True,
        )


# ============================================================
# ê³µê°œ API
# ============================================================

def suggest_refactor(
    current: SandwichScore,
    module_type: ModuleType,
    cognitive_result: CognitiveResult | None = None,
    max_recommendations: int = 3,
) -> list[Recommendation]:
    """
    ë¦¬íŒ©í† ë§ ê¶Œì¥ì‚¬í•­ ìƒì„±

    Args:
        current: í˜„ì¬ SandwichScore
        module_type: ëª¨ë“ˆ íƒ€ì…
        cognitive_result: Cognitive ë¶„ì„ ê²°ê³¼ (ì„ íƒ)
        max_recommendations: ìµœëŒ€ ê¶Œì¥ì‚¬í•­ ìˆ˜

    Returns:
        ìš°ì„ ìˆœìœ„ìˆœ ì •ë ¬ëœ ê¶Œì¥ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
    """
    recommender = GradientRecommender(current, module_type, cognitive_result)
    return recommender.recommend(max_recommendations)


def get_priority_action(
    current: SandwichScore,
    module_type: ModuleType,
) -> Recommendation | None:
    """
    ê°€ì¥ ìš°ì„ ìˆœìœ„ ë†’ì€ ì•¡ì…˜ ë°˜í™˜

    Args:
        current: í˜„ì¬ SandwichScore
        module_type: ëª¨ë“ˆ íƒ€ì…

    Returns:
        ìµœìš°ì„  ê¶Œì¥ì‚¬í•­ ë˜ëŠ” None (ì´ë¯¸ ê· í˜•)
    """
    recommendations = suggest_refactor(current, module_type, max_recommendations=1)
    return recommendations[0] if recommendations else None
