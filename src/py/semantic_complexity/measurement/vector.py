"""
5D Î≥µÏû°ÎèÑ Î≤°ÌÑ∞ Ï∏°Ï†ï

Î≤°ÌÑ∞ Íµ¨ÏÑ±:
- C: Control (Ï†úÏñ¥ ÌùêÎ¶Ñ Î≥µÏû°ÎèÑ)
- N: Nesting (Ï§ëÏ≤© ÍπäÏù¥)
- S: State (ÏÉÅÌÉú Î≥µÏû°ÎèÑ)
- A: Async (ÎπÑÎèôÍ∏∞ Î≥µÏû°ÎèÑ)
- L: Lambda/Coupling (Í≤∞Ìï©ÎèÑ)
"""

__module_type__ = "lib/domain"

import ast
from dataclasses import dataclass, field
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    import numpy as np
    from numpy.typing import NDArray

from .evidence import Location, RuleHit


@dataclass
class ComplexityVector:
    """5D Î≥µÏû°ÎèÑ Î≤°ÌÑ∞

    x_u = [C, N, S, A, Œõ]

    Hodge bucket Î∂ÑÎ•ò:
    - algorithmic  = C + N     (üßÄ Cheese)
    - balanced     = A
    - architectural = S + Œõ    (üçû Bread + ü•ì Ham)
    """
    C: float    # Control
    N: float    # Nesting
    S: float    # State
    A: float    # Async
    L: float    # Coupling (Œõ)

    def to_array(self) -> "NDArray[np.float64]":
        """NumPy Î∞∞Ïó¥Î°ú Î≥ÄÌôò"""
        import numpy as np
        return np.array([self.C, self.N, self.S, self.A, self.L], dtype=np.float64)

    @classmethod
    def from_array(cls, arr: "NDArray[np.float64]") -> "ComplexityVector":
        """NumPy Î∞∞Ïó¥ÏóêÏÑú ÏÉùÏÑ±"""
        return cls(C=float(arr[0]), N=float(arr[1]), S=float(arr[2]),
                   A=float(arr[3]), L=float(arr[4]))

    @classmethod
    def zero(cls) -> "ComplexityVector":
        """ÏòÅÎ≤°ÌÑ∞"""
        return cls(C=0.0, N=0.0, S=0.0, A=0.0, L=0.0)

    @property
    def raw_sum(self) -> float:
        """Î≤°ÌÑ∞ ÏöîÏÜå Ìï©"""
        return self.C + self.N + self.S + self.A + self.L

    def to_dict(self) -> dict[str, float]:
        """dict Î≥ÄÌôò"""
        return {"C": self.C, "N": self.N, "S": self.S, "A": self.A, "L": self.L}


@dataclass
class VectorMeasurement:
    """Î≤°ÌÑ∞ Ï∏°Ï†ï Í≤∞Í≥º"""
    vector: ComplexityVector
    rule_hits: list[RuleHit] = field(default_factory=list)


class VectorAnalyzer:
    """5D Î≥µÏû°ÎèÑ Î≤°ÌÑ∞ Î∂ÑÏÑùÍ∏∞

    ÏÜåÏä§ ÏΩîÎìúÎ•º ASTÎ°ú ÌååÏã±ÌïòÏó¨ 5D Î≤°ÌÑ∞Î•º Ï∏°Ï†ï.
    Í∞Å Ï∏°Ï†ïÎßàÎã§ RuleHitÏúºÎ°ú Í∑ºÍ±∞(evidence) ÏàòÏßë.
    """

    def measure(
        self,
        source: str,
        entity_id: str,
        snapshot_id: str,
        file_path: str = "",
    ) -> VectorMeasurement:
        """5D Î≤°ÌÑ∞ Ï∏°Ï†ï

        Args:
            source: Python ÏÜåÏä§ ÏΩîÎìú
            entity_id: ÏóîÌã∞Ìã∞ ID
            snapshot_id: Ïä§ÎÉÖÏÉ∑ ID
            file_path: ÌååÏùº Í≤ΩÎ°ú (LocationÏö©)

        Returns:
            VectorMeasurement (vector + rule_hits)
        """
        try:
            tree = ast.parse(source)
        except SyntaxError:
            return VectorMeasurement(vector=ComplexityVector.zero())

        rule_hits: list[RuleHit] = []

        # C: Control flow
        control = self._measure_control(tree, entity_id, snapshot_id, file_path, rule_hits)

        # N: Nesting depth
        nesting = self._measure_nesting(tree, entity_id, snapshot_id, file_path, rule_hits)

        # S: State complexity
        state = self._measure_state(tree, entity_id, snapshot_id, file_path, rule_hits)

        # A: Async complexity
        async_val = self._measure_async(tree, entity_id, snapshot_id, file_path, rule_hits)

        # Œõ: Coupling
        coupling = self._measure_coupling(tree, entity_id, snapshot_id, file_path, rule_hits)

        vector = ComplexityVector(
            C=control,
            N=nesting,
            S=state,
            A=async_val,
            L=coupling,
        )

        return VectorMeasurement(vector=vector, rule_hits=rule_hits)

    def _measure_control(
        self,
        tree: ast.AST,
        entity_id: str,
        snapshot_id: str,
        file_path: str,
        hits: list[RuleHit],
    ) -> float:
        """Ï†úÏñ¥ ÌùêÎ¶Ñ Î≥µÏû°ÎèÑ Ï∏°Ï†ï

        Î∂ÑÍ∏∞Î¨∏(if, for, while, try, match, with) Í∞úÏàò Ïπ¥Ïö¥Ìä∏.
        """
        count = 0
        locations: list[Location] = []

        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.For, ast.While, ast.Try,
                                  ast.Match, ast.With)):
                count += 1
                locations.append(Location(
                    file=file_path,
                    line=node.lineno,
                    column=node.col_offset,
                    ast_node_type=type(node).__name__,
                ))

        if locations:
            hits.append(RuleHit(
                entity_id=entity_id,
                snapshot_id=snapshot_id,
                rule_id="control/branch",
                count=count,
                locations=locations,
            ))

        return float(count)

    def _measure_nesting(
        self,
        tree: ast.AST,
        entity_id: str,
        snapshot_id: str,
        file_path: str,
        hits: list[RuleHit],
    ) -> float:
        """Ï§ëÏ≤© ÍπäÏù¥ Ï∏°Ï†ï

        ÏµúÎåÄ Ï§ëÏ≤© ÍπäÏù¥ Ï∂îÏ†Å.
        """
        max_depth = 0
        deepest_location: Location | None = None

        def walk_depth(node: ast.AST, depth: int = 0) -> None:
            nonlocal max_depth, deepest_location

            # Ï§ëÏ≤© Ï¶ùÍ∞Ä ÎÖ∏Îìú
            if isinstance(node, (ast.If, ast.For, ast.While, ast.Try,
                                  ast.With, ast.FunctionDef, ast.AsyncFunctionDef)):
                depth += 1
                if depth > max_depth:
                    max_depth = depth
                    deepest_location = Location(
                        file=file_path,
                        line=node.lineno,
                        column=node.col_offset,
                        ast_node_type=type(node).__name__,
                    )

            for child in ast.iter_child_nodes(node):
                walk_depth(child, depth)

        walk_depth(tree)

        if deepest_location:
            hits.append(RuleHit(
                entity_id=entity_id,
                snapshot_id=snapshot_id,
                rule_id="nesting/depth",
                count=max_depth,
                locations=[deepest_location],
            ))

        return float(max_depth)

    def _measure_state(
        self,
        tree: ast.AST,
        entity_id: str,
        snapshot_id: str,
        file_path: str,
        hits: list[RuleHit],
    ) -> float:
        """ÏÉÅÌÉú Î≥µÏû°ÎèÑ Ï∏°Ï†ï

        - global Î¨∏
        - nonlocal Î¨∏
        - ÌÅ¥ÎûòÏä§ ÏÜçÏÑ± mutation (self.xxx = yyy)
        """
        count = 0
        locations: list[Location] = []

        for node in ast.walk(tree):
            # global/nonlocal
            if isinstance(node, (ast.Global, ast.Nonlocal)):
                count += len(node.names)
                locations.append(Location(
                    file=file_path,
                    line=node.lineno,
                    column=node.col_offset,
                    ast_node_type=type(node).__name__,
                ))
            # self.xxx = yyy
            elif isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Attribute):
                        if isinstance(target.value, ast.Name) and target.value.id == "self":
                            count += 1
                            locations.append(Location(
                                file=file_path,
                                line=node.lineno,
                                column=node.col_offset,
                                ast_node_type="SelfAttributeAssign",
                            ))

        if locations:
            hits.append(RuleHit(
                entity_id=entity_id,
                snapshot_id=snapshot_id,
                rule_id="state/mutation",
                count=count,
                locations=locations,
            ))

        return float(count)

    def _measure_async(
        self,
        tree: ast.AST,
        entity_id: str,
        snapshot_id: str,
        file_path: str,
        hits: list[RuleHit],
    ) -> float:
        """ÎπÑÎèôÍ∏∞ Î≥µÏû°ÎèÑ Ï∏°Ï†ï

        - async def
        - await
        - async for
        - async with
        """
        count = 0
        locations: list[Location] = []

        for node in ast.walk(tree):
            if isinstance(node, ast.AsyncFunctionDef):
                count += 1
                locations.append(Location(
                    file=file_path,
                    line=node.lineno,
                    column=node.col_offset,
                    ast_node_type="AsyncFunctionDef",
                ))
            elif isinstance(node, ast.Await):
                count += 1
                locations.append(Location(
                    file=file_path,
                    line=node.lineno,
                    column=node.col_offset,
                    ast_node_type="Await",
                ))
            elif isinstance(node, ast.AsyncFor):
                count += 1
                locations.append(Location(
                    file=file_path,
                    line=node.lineno,
                    column=node.col_offset,
                    ast_node_type="AsyncFor",
                ))
            elif isinstance(node, ast.AsyncWith):
                count += 1
                locations.append(Location(
                    file=file_path,
                    line=node.lineno,
                    column=node.col_offset,
                    ast_node_type="AsyncWith",
                ))

        if locations:
            hits.append(RuleHit(
                entity_id=entity_id,
                snapshot_id=snapshot_id,
                rule_id="async/complexity",
                count=count,
                locations=locations,
            ))

        return float(count)

    def _measure_coupling(
        self,
        tree: ast.AST,
        entity_id: str,
        snapshot_id: str,
        file_path: str,
        hits: list[RuleHit],
    ) -> float:
        """Í≤∞Ìï©ÎèÑ Ï∏°Ï†ï

        - import Î¨∏ Í∞úÏàò
        - Ìï®Ïàò ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò (Í≥ºÎã§ ÌååÎùºÎØ∏ÌÑ∞)
        """
        import_count = 0
        param_violations = 0
        locations: list[Location] = []

        for node in ast.walk(tree):
            # import
            if isinstance(node, (ast.Import, ast.ImportFrom)):
                import_count += 1
                locations.append(Location(
                    file=file_path,
                    line=node.lineno,
                    column=node.col_offset,
                    ast_node_type="Import",
                ))
            # Í≥ºÎã§ ÌååÎùºÎØ∏ÌÑ∞ (> 5)
            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                args = node.args
                total_params = (
                    len(args.posonlyargs) +
                    len(args.args) +
                    len(args.kwonlyargs) +
                    (1 if args.vararg else 0) +
                    (1 if args.kwarg else 0)
                )
                # self/cls Ï†úÏô∏
                if args.args and args.args[0].arg in ("self", "cls"):
                    total_params -= 1

                if total_params > 5:
                    param_violations += 1
                    locations.append(Location(
                        file=file_path,
                        line=node.lineno,
                        column=node.col_offset,
                        ast_node_type="ExcessiveParams",
                    ))

        # Í≤∞Ìï©ÎèÑ = import Ïàò * 0.5 + ÌååÎùºÎØ∏ÌÑ∞ ÏúÑÎ∞ò * 2
        coupling = import_count * 0.5 + param_violations * 2.0

        if locations:
            hits.append(RuleHit(
                entity_id=entity_id,
                snapshot_id=snapshot_id,
                rule_id="coupling/dependency",
                count=import_count + param_violations,
                locations=locations,
            ))

        return coupling


# ============================================================
# Í≥µÍ∞ú API
# ============================================================

__all__ = [
    "ComplexityVector",
    "VectorMeasurement",
    "VectorAnalyzer",
]
