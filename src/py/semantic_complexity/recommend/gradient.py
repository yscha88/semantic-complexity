"""
Gradient-based Recommender

ê· í˜•ì ìœ¼ë¡œ í–¥í•˜ëŠ” ë¦¬íŒ©í† ë§ ê¶Œìž¥ì‚¬í•­ ìƒì„±
"""

__architecture_role__ = "lib/domain"

from dataclasses import dataclass
from typing import Literal

from ..types import Axis, ArchitectureRole, SandwichScore, get_canonical_profile
from ..simplex import (
    GradientDirection,
    EquilibriumStatus,
    check_equilibrium,
    calculate_deviation,
)
from ..analyzers import CognitiveAnalysis


@dataclass
class Recommendation:
    """ë¦¬íŒ©í† ë§ ê¶Œìž¥ì‚¬í•­"""
    axis: Axis
    priority: int  # 1 = ìµœìš°ì„ 
    action: str
    reason: str
    expected_impact: dict[str, float]  # {"ðŸž": -5, "ðŸ§€": +3, ...}
    target_equilibrium: bool  # Trueë©´ ê· í˜•ì  ë°©í–¥


# ============================================================
# ì¶•ë³„ ë¦¬íŒ©í† ë§ ì•¡ì…˜
# ============================================================

BREAD_ACTIONS = {
    "increase": [
        ("ì‹ ë¢° ê²½ê³„ ëª…ì‹œì  ì •ì˜ ì¶”ê°€", "Trust boundaryë¥¼ ì½”ë“œì— ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„"),
        ("ì¸ì¦/ì¸ê°€ ë°ì½”ë ˆì´í„° ì ìš©", "ì—”ë“œí¬ì¸íŠ¸ì— @authenticated ë“± ì ìš©"),
        ("ìž…ë ¥ ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€", "ì™¸ë¶€ ìž…ë ¥ì— ëŒ€í•œ ê²€ì¦ ë¡œì§ ì¶”ê°€"),
    ],
    "decrease": [
        ("ë³´ì•ˆ ë¡œì§ ë¶„ë¦¬", "ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì—ì„œ ë³´ì•ˆ ë¡œì§ ë¶„ë¦¬"),
        ("ê³µí†µ ë³´ì•ˆ ë¯¸ë“¤ì›¨ì–´ë¡œ ì¶”ì¶œ", "ë°˜ë³µë˜ëŠ” ë³´ì•ˆ ë¡œì§ì„ ë¯¸ë“¤ì›¨ì–´ë¡œ"),
    ],
}

CHEESE_ACTIONS = {
    "increase": [
        # ðŸ§€ increaseëŠ” ë“œë¬¸ ì¼€ì´ìŠ¤ (ë³µìž¡ë„ê°€ ë„ˆë¬´ ë‚®ìŒ)
        ("ì ì ˆí•œ ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€", "ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬ ë¡œì§ ì¶”ê°€"),
    ],
    "decrease": [
        ("ì¤‘ì²© í‰íƒ„í™” (early return)", "ê¹Šì€ ì¤‘ì²©ì„ early returnìœ¼ë¡œ í‰íƒ„í™”"),
        ("í•¨ìˆ˜ ì¶”ì¶œ (Extract Function)", "ë³µìž¡í•œ ë¸”ë¡ì„ ë³„ë„ í•¨ìˆ˜ë¡œ ì¶”ì¶œ (íŒŒë¼ë¯¸í„° ë¬¶ê¸° ê¸ˆì§€)"),
        ("ì¡°ê±´ ë‹¨ìˆœí™”", "ë³µìž¡í•œ ì¡°ê±´ì„ ëª…ëª…ëœ ë³€ìˆ˜ë¡œ ë¶„ë¦¬"),
        ("ìƒíƒœ ë¶„ë¦¬", "stateÃ—asyncÃ—retry ë¶„ë¦¬"),
        ("Switch â†’ ë‹¤í˜•ì„±", "switch/matchë¥¼ Strategy íŒ¨í„´ìœ¼ë¡œ"),
    ],
}

# ðŸš« Anti-pattern ê²½ê³  (LLMì´ ì‚¬ìš©í•˜ë©´ ì•ˆ ë˜ëŠ” íŽ¸ë²•)
CHEESE_ANTI_PATTERNS = [
    ("*args/**kwargs ì‚¬ìš© ê¸ˆì§€", "*args, **kwargsë¡œ íŒŒë¼ë¯¸í„° ìˆ¨ê¸°ê¸°ëŠ” ë³µìž¡ë„ íšŒí”¼ íŽ¸ë²•"),
    ("Config ê°ì²´ bundling ê¸ˆì§€", "ê´€ë ¨ ì—†ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ config ê°ì²´ë¡œ ë¬¶ì§€ ë§ ê²ƒ"),
    ("Tuple/Dict íŒŒë¼ë¯¸í„° ê¸ˆì§€", "params: tuple, options: dict í˜•íƒœë¡œ ì˜ë¯¸ ìˆ¨ê¸°ê¸° ê¸ˆì§€"),
    ("ì¸ë¼ì¸ ì¹˜í™˜ ê¸ˆì§€", "ëª…ëª…ëœ ë³€ìˆ˜ë¥¼ ì¸ë¼ì¸ í‘œí˜„ì‹ìœ¼ë¡œ ëŒ€ì²´í•˜ì§€ ë§ ê²ƒ"),
]

HAM_ACTIONS = {
    "increase": [
        ("Golden test ì¶”ê°€", "Critical pathì— ëŒ€í•œ golden test ìž‘ì„±"),
        ("Contract test ì¶”ê°€", "API ê³„ì•½ í…ŒìŠ¤íŠ¸ ìž‘ì„±"),
        ("Test fixture ì •ë¦¬", "í…ŒìŠ¤íŠ¸ ì½”ë“œ êµ¬ì¡°í™”"),
    ],
    "decrease": [
        # ðŸ¥“ decreaseëŠ” ë“œë¬¸ ì¼€ì´ìŠ¤ (í…ŒìŠ¤íŠ¸ê°€ ë„ˆë¬´ ë§ŽìŒ?!)
        ("ì¤‘ë³µ í…ŒìŠ¤íŠ¸ ì •ë¦¬", "ë¶ˆí•„ìš”í•œ ì¤‘ë³µ í…ŒìŠ¤íŠ¸ ì œê±°"),
    ],
}

AXIS_ACTIONS = {
    Axis.BREAD: BREAD_ACTIONS,
    Axis.CHEESE: CHEESE_ACTIONS,
    Axis.HAM: HAM_ACTIONS,
}


class GradientRecommender:
    """Gradient ê¸°ë°˜ ê¶Œìž¥ì‚¬í•­ ìƒì„±ê¸°"""

    def __init__(
        self,
        current: SandwichScore,
        architecture_role: ArchitectureRole,
        cognitive_result: CognitiveAnalysis | None = None,
    ):
        self.current = current
        self.architecture_role = architecture_role
        self.profile = get_canonical_profile(architecture_role)
        self.cognitive_result = cognitive_result

    def recommend(self, max_recommendations: int = 3) -> list[Recommendation]:
        """
        ë¦¬íŒ©í† ë§ ê¶Œìž¥ì‚¬í•­ ìƒì„±

        Args:
            max_recommendations: ìµœëŒ€ ê¶Œìž¥ì‚¬í•­ ìˆ˜

        Returns:
            ìš°ì„ ìˆœìœ„ìˆœ ì •ë ¬ëœ ê¶Œìž¥ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
        """
        status = check_equilibrium(self.current, self.profile)

        if status.in_equilibrium:
            return []  # ì´ë¯¸ ê· í˜•

        recommendations: list[Recommendation] = []

        for i, gradient in enumerate(status.gradients[:max_recommendations]):
            rec = self._create_recommendation(gradient, priority=i + 1)
            if rec:
                recommendations.append(rec)

        # stateÃ—asyncÃ—retry ìœ„ë°˜ ì‹œ ì¶”ê°€ ê¶Œìž¥ì‚¬í•­
        if self.cognitive_result and self.cognitive_result.state_async_retry.violated:
            recommendations.insert(0, Recommendation(
                axis=Axis.CHEESE,
                priority=0,  # ìµœìš°ì„ 
                action="stateÃ—asyncÃ—retry ë¶„ë¦¬",
                reason="ì¸ì§€ ë¶ˆë³€ì¡°ê±´ ìœ„ë°˜ - ìƒíƒœ, ë¹„ë™ê¸°, ìž¬ì‹œë„ ë¡œì§ì„ ë¶„ë¦¬í•´ì•¼ í•¨",
                expected_impact={"ðŸ§€": -20.0},
                target_equilibrium=True,
            ))

        return recommendations

    def _create_recommendation(
        self,
        gradient: GradientDirection,
        priority: int,
    ) -> Recommendation | None:
        """Gradientì—ì„œ ê¶Œìž¥ì‚¬í•­ ìƒì„±"""
        actions = AXIS_ACTIONS.get(gradient.axis, {})
        direction_actions = actions.get(gradient.direction, [])

        if not direction_actions:
            return None

        action, reason = direction_actions[0]

        # Expected impact ê³„ì‚°
        impact_value = -gradient.magnitude if gradient.direction == "decrease" else gradient.magnitude
        impact = {str(gradient.axis): impact_value}

        return Recommendation(
            axis=gradient.axis,
            priority=priority,
            action=action,
            reason=reason,
            expected_impact=impact,
            target_equilibrium=True,
        )


# ============================================================
# ê³µê°œ API
# ============================================================

def suggest_refactor(
    current: SandwichScore,
    architecture_role: ArchitectureRole,
    cognitive_result: CognitiveAnalysis | None = None,
    max_recommendations: int = 3,
) -> list[Recommendation]:
    """
    ë¦¬íŒ©í† ë§ ê¶Œìž¥ì‚¬í•­ ìƒì„±

    Args:
        current: í˜„ìž¬ SandwichScore
        architecture_role: ëª¨ë“ˆ íƒ€ìž…
        cognitive_result: Cognitive ë¶„ì„ ê²°ê³¼ (ì¸ì§€ ê°€ëŠ¥ ì—¬ë¶€)
        max_recommendations: ìµœëŒ€ ê¶Œìž¥ì‚¬í•­ ìˆ˜

    Returns:
        ìš°ì„ ìˆœìœ„ìˆœ ì •ë ¬ëœ ê¶Œìž¥ì‚¬í•­ ë¦¬ìŠ¤íŠ¸
    """
    recommender = GradientRecommender(current, architecture_role, cognitive_result)
    return recommender.recommend(max_recommendations)


def get_priority_action(
    current: SandwichScore,
    architecture_role: ArchitectureRole,
) -> Recommendation | None:
    """
    ê°€ìž¥ ìš°ì„ ìˆœìœ„ ë†’ì€ ì•¡ì…˜ ë°˜í™˜

    Args:
        current: í˜„ìž¬ SandwichScore
        architecture_role: ëª¨ë“ˆ íƒ€ìž…

    Returns:
        ìµœìš°ì„  ê¶Œìž¥ì‚¬í•­ ë˜ëŠ” None (ì´ë¯¸ ê· í˜•)
    """
    recommendations = suggest_refactor(current, architecture_role, max_recommendations=1)
    return recommendations[0] if recommendations else None


# ============================================================
# ì¸ì§€ ì €í•˜ íƒì§€
# ============================================================

@dataclass
class DegradationResult:
    """ì¸ì§€ ì €í•˜ íƒì§€ ê²°ê³¼"""
    degraded: bool
    severity: Literal["none", "mild", "moderate", "severe"]
    indicators: list[str]
    before_accessible: bool
    after_accessible: bool
    delta_nesting: int
    delta_hidden_deps: int
    delta_violations: int


def check_degradation(
    before: CognitiveAnalysis,
    after: CognitiveAnalysis,
) -> DegradationResult:
    """
    ì¸ì§€ ì €í•˜ íƒì§€ - ì½”ë“œ ë³€ê²½ì´ ì¸ì§€ì„±ì„ ì•…í™”ì‹œì¼°ëŠ”ì§€ í™•ì¸

    WHEN TO USE:
    - PR ë¦¬ë·° ì‹œ ì¸ì§€ì„± ì•…í™” ì—¬ë¶€ í™•ì¸
    - ë¦¬íŒ©í† ë§ ì „í›„ ë¹„êµ
    - ê¸°ìˆ  ë¶€ì±„ ì¶”ì 

    ì €í•˜ ì§€í‘œ:
    1. accessible True â†’ False ì „í™˜
    2. ì¤‘ì²© ê¹Šì´ ì¦ê°€
    3. ìˆ¨ê²¨ì§„ ì˜ì¡´ì„± ì¦ê°€
    4. stateÃ—asyncÃ—retry ìœ„ë°˜ ë°œìƒ

    Args:
        before: ë³€ê²½ ì „ CognitiveAnalysis
        after: ë³€ê²½ í›„ CognitiveAnalysis

    Returns:
        DegradationResult: ì €í•˜ ì—¬ë¶€ ë° ì‹¬ê°ë„
    """
    indicators: list[str] = []

    # 1. ì¸ì§€ ê°€ëŠ¥ ìƒíƒœ ì „í™˜
    accessibility_lost = before.accessible and not after.accessible
    if accessibility_lost:
        indicators.append("ì¸ì§€ ê°€ëŠ¥ ìƒíƒœ ìƒì‹¤ (accessible: True â†’ False)")

    # 2. ì¤‘ì²© ê¹Šì´ ì¦ê°€
    delta_nesting = after.max_nesting - before.max_nesting
    if delta_nesting > 0:
        indicators.append(f"ì¤‘ì²© ê¹Šì´ ì¦ê°€: +{delta_nesting} ({before.max_nesting} â†’ {after.max_nesting})")

    # 3. ìˆ¨ê²¨ì§„ ì˜ì¡´ì„± ì¦ê°€
    delta_hidden = len(after.hidden_dependencies) - len(before.hidden_dependencies)
    if delta_hidden > 0:
        indicators.append(f"ìˆ¨ê²¨ì§„ ì˜ì¡´ì„± ì¦ê°€: +{delta_hidden}")

    # 4. stateÃ—asyncÃ—retry ìœ„ë°˜ ë°œìƒ
    sar_before = before.state_async_retry.violated
    sar_after = after.state_async_retry.violated
    if not sar_before and sar_after:
        indicators.append(f"stateÃ—asyncÃ—retry ìœ„ë°˜ ë°œìƒ: {' Ã— '.join(after.state_async_retry.axes)}")

    # 5. ìœ„ë°˜ ì‚¬í•­ ì¦ê°€
    delta_violations = len(after.violations) - len(before.violations)
    if delta_violations > 0:
        indicators.append(f"ìœ„ë°˜ ì‚¬í•­ ì¦ê°€: +{delta_violations}")

    # ì‹¬ê°ë„ íŒì •
    severity: Literal["none", "mild", "moderate", "severe"]
    if not indicators:
        severity = "none"
    elif accessibility_lost:
        severity = "severe"
    elif len(indicators) >= 3:
        severity = "severe"
    elif len(indicators) >= 2:
        severity = "moderate"
    else:
        severity = "mild"

    return DegradationResult(
        degraded=len(indicators) > 0,
        severity=severity,
        indicators=indicators,
        before_accessible=before.accessible,
        after_accessible=after.accessible,
        delta_nesting=delta_nesting,
        delta_hidden_deps=delta_hidden,
        delta_violations=delta_violations,
    )
